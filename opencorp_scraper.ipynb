{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CountryScraper(object):\n",
    "    def __init__(self):\n",
    "        self.driver = webdriver.Chrome()\n",
    "        #use whatever driver engine you have in path (e.g.: Firefox, IE, Safari, Opera)\n",
    "\n",
    "    def scrape(self):\n",
    "        self.driver.get(\"https://opencorporates.com/companies/sk?page=1&q=&utf8=%E2%9C%93\")\n",
    "        #open page with a driver\n",
    "        soup = BS(self.driver.page_source, 'html.parser')\n",
    "        writer = csv.DictWriter(open('where_sample.csv', 'w'), fieldnames = 'name country'.split(' '))\n",
    "        writer.writeheader()\n",
    "        for firm in soup.find_all('a', {'class':'company_search_result'}):\n",
    "            title = firm.get('title').split(' ',7)[7]\n",
    "            name  = title.split('(', 1)[0][1:-2]\n",
    "            country = title.split('(',1)[1][0:8]\n",
    "            dictionary = {'name': name, 'country': country}\n",
    "            #get the name of the firm and the country it is in\n",
    "            writer.writerow(dictionary)\n",
    "        self.driver.close()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    scraper = CountryScraper()\n",
    "    scraper.scrape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://opencorporates.com/companies/hr?commit=Go&inactive=false&order=&page=1&q=&utf8=%E2%9C%93\"\n",
    "driver = webdriver.Chrome()    \n",
    "driver.get(link)\n",
    "soup = unidecode(BS(driver.page_source, 'html.parser'))\n",
    "sk = re.compile(r'[0-9]+, ([A-Za-z\\s\\/\\(\\)\\.]+)[,\\s0-9\\<]*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Štorije \"', 'Croatia', ' Punat']\n",
      "[' ŽELJA UMA \"', 'Croatia', ' Velika']\n",
      "['Antenor\"', 'Croatia', ' Zrnovo']\n",
      "['BASKET-GRADAC\"', 'Croatia', ' Gradac']\n",
      "['BIBI\" D.O.O. U LIKVIDACIJI', 'Croatia', ' Rijeka-dio']\n",
      "['BONKULOVIĆI\" - KORČULA', 'Croatia', ' Korcula']\n",
      "['BRESKORKA\"', 'Croatia', ' Tovarnik']\n",
      "['BVC\"', 'Croatia', ' Zagreb']\n",
      "['DALONG\"', 'Croatia', ' Zagreb']\n",
      "['DECOM\"', 'Croatia', ' Zagreb']\n",
      "['DOMING\"', 'Croatia', ' Zagreb']\n",
      "['DOSTOJAN ŽIVOT\" UDRUGA ZA ZAŠTITU LJUDSKIH PRAVA', 'Croatia', ' Zagreb']\n",
      "['DRAGO\"', 'Croatia', ' Zagreb']\n",
      "['Dobri duh\"- terapijsko, rekreacijsko i sportsko jahanje za osobe s posebnim potrebama', 'Croatia', ' Majerje']\n",
      "['DraCon\"- Dubrovačka cosplay organizacija', 'Croatia', ' Dubrovnik']\n",
      "['EKO FURKA\"', 'Croatia', ' Zagreb']\n",
      "['EM-BEDER\" D.O.O. ŽEPČE', 'Croatia', ' Pula']\n",
      "['EURO LISICA\" d.o.o.', 'Croatia', ' Petrijanec']\n",
      "['Ekipa\"', 'Croatia', ' Split']\n",
      "['FEREX\" d.o.o. u likvidaciji', 'Croatia', ' Pula']\n",
      "['GU\" BELJEVINA', 'Croatia', ' Beljevina']\n",
      "['HALILOVIĆ\"', 'Croatia', ' Sesvete']\n",
      "['HOPE\" H.P.Ž.', 'Croatia', ' Pula']\n",
      "['HRVATSKI FENIKS\" SPLIT', 'Croatia', ' Split']\n",
      "['HVIDR-a\" Požeško-slavonske županije', 'Croatia', ' Pozega']\n",
      "['ICO-KOMERC\" D.O.O. U LIKVIDACIJI', 'Croatia', ' Novi']\n",
      "['INSTITUT ZA INDUSTRIJSKI RAZVOJ\"', 'Croatia', ' Zagreb']\n",
      "['IRENET\"', 'Croatia', ' Zagreb']\n",
      "['KAŠTELINA\" KAŠIĆ', 'Croatia', ' Kasic']\n",
      "['KOPRIVICE SENJ\"', 'Croatia', ' Senj']\n"
     ]
    }
   ],
   "source": [
    "for firm in soup.find_all('li', {'class':'search-result company '}):\n",
    "    title_res = firm.find('a', {'class' : 'company_search_result'})\n",
    "    add_res = firm.find('span', {'class': 'address'})\n",
    "    add = unidecode(str(firm))\n",
    "    title = title_res.get('title').split(' ', 7)[7]\n",
    "    name = title.split('(', 1)[0][1:-1]\n",
    "    country = title.split('(',1)[1].split(',')[0]\n",
    "    if country != \"Poland\":\n",
    "        if country == \"Croatia\":\n",
    "            city = add.split(',')[-2]\n",
    "        if country == \"Slovenia\":\n",
    "            city = add.split(\" \")[-1].split(\"<\")[0]\n",
    "    else:\n",
    "        city = \"\"\n",
    "    print([name,country,city])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-20-011287c13e9e>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-011287c13e9e>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    for firm in soup.find_all('li',{'class':'search-result company v_lividácii'}):\u001b[0m\n\u001b[0m                                                                                  ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#slovakia\n",
    "for firm in soup.find_all('li', {'class':'search-result company '}):\n",
    "    title_res = firm.find('a', {'class' : 'company_search_result'})\n",
    "    add_res = firm.find('span', {'class': 'address'})\n",
    "    add = str(firm)\n",
    "    title = title_res.get('title').split(' ', 7)[7]\n",
    "    name = title.split('(', 1)[0][1:-1]\n",
    "    country = title.split('(',1)[1][0:8]\n",
    "    try:\n",
    "        city = sk.search(add).groups()\n",
    "    except AttributeError:\n",
    "        city = \"\"\n",
    "    print(city)\n",
    "\n",
    "for firm in soup.find_all('li',{'class':'search-result company v_lividácii'}):\n",
    "    title_res = firm.find('a', {'class' : 'company_search_result'})\n",
    "    add_res = firm.find('span', {'class': 'address'})\n",
    "    add = str(firm)\n",
    "    title = title_res.get('title').split(' ', 7)[7]\n",
    "    name = title.split('(', 1)[0][1:-1]\n",
    "    country = title.split('(',1)[1][0:8]\n",
    "    try:\n",
    "        city = sk.search(add).groups()\n",
    "    except AttributeError:\n",
    "        city = \"\"\n",
    "    print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sat Răteşti\n",
      " Sat Săftica\n",
      " Sat Gugeşti\n",
      " Municipiul Sibiu\n",
      " Municipiul Sfântu Gheorghe\n",
      " Sat Băţanii Mari\n",
      " Municipiul Sibiu\n",
      " Sat Barcani\n",
      " Bucureşti Sectorul 3\n",
      " Loc. Întorsura Buzăului\n",
      " Municipiul Sfântu Gheorghe\n",
      " Municipiul Sfântu Gheorghe\n",
      " Municipiul Sfântu Gheorghe\n",
      " Municipiul Sfântu Gheorghe\n",
      " Loc. Întorsura Buzăului\n",
      " Sat Comandău\n",
      " Municipiul Târgu Secuiesc\n",
      " Municipiul Sfântu Gheorghe\n"
     ]
    }
   ],
   "source": [
    "#romania\n",
    "for firm in soup.find_all('li', {'class':'search-result company '}):\n",
    "    title_res = firm.find('a', {'class' : 'company_search_result'})\n",
    "    add_res = firm.find('span', {'class': 'address'})\n",
    "    add = str(firm)\n",
    "    title = title_res.get('title').split(' ', 7)[7]\n",
    "    name = title.split('(', 1)[0][1:-1]\n",
    "    country = title.split('(',1)[1][0:8]\n",
    "    city = add.split(',')[-1].split('<')[0]\n",
    "    print(city)\n",
    "\n",
    "for firm in soup.find_all('li',{'class':'search-result company functiune'}):\n",
    "    title_res = firm.find('a', {'class' : 'company_search_result'})\n",
    "    add_res = firm.find('span', {'class': 'address'})\n",
    "    add = str(firm)\n",
    "    title = title_res.get('title').split(' ', 7)[7]\n",
    "    name = title.split('(', 1)[0][1:-1]\n",
    "    country = title.split('(',1)[1][0:8]\n",
    "    city = add.split(',')[-1].split('<')[0]\n",
    "    print(city)\n",
    "\n",
    "for firm in soup.find_all('li',{'class':'search-result company intrerupere_temporara_de_activitate'}):\n",
    "    title_res = firm.find('a', {'class' : 'company_search_result'})\n",
    "    add_res = firm.find('span', {'class': 'address'})\n",
    "    add = str(firm)\n",
    "    title = title_res.get('title').split(' ', 7)[7]\n",
    "    name = title.split('(', 1)[0][1:-1]\n",
    "    country = title.split('(',1)[1][0:8]\n",
    "    city = add.split(',')[-1].split('<')[0]\n",
    "    print(city)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
